{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification and regression with genepro\n",
    "A Scikit-learn compatible classifier and regressor is already provided in genepro. This notebook show how they can be used.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification\n",
    "At the moment, genepro supports binary classification. The reason why multi-class is not supported is that the output of a tree is its root, hence a multi-tree representation is required to realize multi-class classification. Here's how binary classification can be performed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen: 1,\tbest of gen fitness: 0.821,\tbest of gen size: 20\n",
      "gen: 2,\tbest of gen fitness: 0.848,\tbest of gen size: 15\n",
      "gen: 3,\tbest of gen fitness: 0.857,\tbest of gen size: 22\n",
      "gen: 4,\tbest of gen fitness: 0.850,\tbest of gen size: 22\n",
      "gen: 5,\tbest of gen fitness: 0.878,\tbest of gen size: 31\n",
      "gen: 6,\tbest of gen fitness: 0.878,\tbest of gen size: 31\n",
      "gen: 7,\tbest of gen fitness: 0.895,\tbest of gen size: 22\n",
      "gen: 8,\tbest of gen fitness: 0.891,\tbest of gen size: 23\n",
      "gen: 9,\tbest of gen fitness: 0.903,\tbest of gen size: 31\n",
      "gen: 10,\tbest of gen fitness: 0.903,\tbest of gen size: 31\n",
      "gen: 11,\tbest of gen fitness: 0.903,\tbest of gen size: 31\n",
      "gen: 12,\tbest of gen fitness: 0.903,\tbest of gen size: 31\n",
      "gen: 13,\tbest of gen fitness: 0.913,\tbest of gen size: 31\n",
      "gen: 14,\tbest of gen fitness: 0.913,\tbest of gen size: 31\n",
      "gen: 15,\tbest of gen fitness: 0.913,\tbest of gen size: 31\n",
      "gen: 16,\tbest of gen fitness: 0.913,\tbest of gen size: 31\n",
      "gen: 17,\tbest of gen fitness: 0.913,\tbest of gen size: 31\n",
      "gen: 18,\tbest of gen fitness: 0.917,\tbest of gen size: 30\n",
      "gen: 19,\tbest of gen fitness: 0.917,\tbest of gen size: 30\n",
      "gen: 20,\tbest of gen fitness: 0.917,\tbest of gen size: 30\n",
      "gen: 21,\tbest of gen fitness: 0.917,\tbest of gen size: 30\n",
      "gen: 22,\tbest of gen fitness: 0.917,\tbest of gen size: 30\n",
      "gen: 23,\tbest of gen fitness: 0.917,\tbest of gen size: 30\n",
      "gen: 24,\tbest of gen fitness: 0.922,\tbest of gen size: 28\n",
      "gen: 25,\tbest of gen fitness: 0.922,\tbest of gen size: 28\n",
      "gen: 26,\tbest of gen fitness: 0.928,\tbest of gen size: 28\n",
      "gen: 27,\tbest of gen fitness: 0.928,\tbest of gen size: 28\n",
      "gen: 28,\tbest of gen fitness: 0.928,\tbest of gen size: 28\n",
      "gen: 29,\tbest of gen fitness: 0.928,\tbest of gen size: 28\n",
      "gen: 30,\tbest of gen fitness: 0.928,\tbest of gen size: 28\n",
      "gen: 31,\tbest of gen fitness: 0.928,\tbest of gen size: 28\n",
      "gen: 32,\tbest of gen fitness: 0.928,\tbest of gen size: 28\n",
      "gen: 33,\tbest of gen fitness: 0.932,\tbest of gen size: 30\n",
      "gen: 34,\tbest of gen fitness: 0.932,\tbest of gen size: 30\n",
      "gen: 35,\tbest of gen fitness: 0.932,\tbest of gen size: 30\n",
      "gen: 36,\tbest of gen fitness: 0.932,\tbest of gen size: 30\n",
      "gen: 37,\tbest of gen fitness: 0.932,\tbest of gen size: 30\n",
      "gen: 38,\tbest of gen fitness: 0.932,\tbest of gen size: 30\n",
      "gen: 39,\tbest of gen fitness: 0.932,\tbest of gen size: 30\n",
      "gen: 40,\tbest of gen fitness: 0.932,\tbest of gen size: 30\n",
      "The balanced accuracy on the test set is 0.867\n",
      "Obtained by the (simplified) model: -x21 - x23 - x26 + log(abs(x26*log(abs(x29)) + 1)) + log(abs(log(abs(log(abs(2*x13))))))\n"
     ]
    }
   ],
   "source": [
    "import sympy\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from genepro.scikit import GeneProClassifier\n",
    "from genepro.node_impl import *\n",
    "\n",
    "# Let's load the Breast Cancer data set from sklearn\n",
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "\n",
    "# Create a train and test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply feature normalization\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Set up what nodes genepro should use\n",
    "internal_nodes = [Plus(), Minus(), Times(), Div(), Log()]\n",
    "# As leaf nodes, let's set up the possibility to use each feature, plus a constant\n",
    "# (this is the default if leaf_nodes are not provided)\n",
    "num_features = X_train.shape[1]\n",
    "leaf_nodes = [Feature(i) for i in range(num_features)] + [Constant()]\n",
    "\n",
    "# Set up classifier\n",
    "gp = GeneProClassifier(balanced_accuracy_score, internal_nodes, leaf_nodes=leaf_nodes, \n",
    "  evo_kwargs={'verbose':True, 'pop_size':128, 'max_gens':40, 'max_tree_size':50, 'n_jobs':4, })\n",
    "\n",
    "# Run\n",
    "gp.fit(X_train, y_train)\n",
    "\n",
    "# Get test (balanced) accuracy\n",
    "test_acc = balanced_accuracy_score(y_test, gp.predict(X_test))\n",
    "print(\"The balanced accuracy on the test set is {:.3f}\".format(test_acc))\n",
    "# Get the best-found tree (at the last generation) and simplify it\n",
    "best_tree = sympy.simplify(gp.evo.best_of_gens[-1].get_readable_repr())\n",
    "print(\"Obtained by the (simplified) model:\", best_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen: 1,\tbest of gen fitness: -4223.681,\tbest of gen size: 1\n",
      "gen: 2,\tbest of gen fitness: -3854.131,\tbest of gen size: 4\n",
      "gen: 3,\tbest of gen fitness: -3824.623,\tbest of gen size: 3\n",
      "gen: 4,\tbest of gen fitness: -3824.623,\tbest of gen size: 3\n",
      "gen: 5,\tbest of gen fitness: -3824.623,\tbest of gen size: 3\n",
      "gen: 6,\tbest of gen fitness: -3824.623,\tbest of gen size: 3\n",
      "gen: 7,\tbest of gen fitness: -3778.230,\tbest of gen size: 25\n",
      "gen: 8,\tbest of gen fitness: -3291.339,\tbest of gen size: 6\n",
      "gen: 9,\tbest of gen fitness: -3322.973,\tbest of gen size: 6\n",
      "gen: 10,\tbest of gen fitness: -3291.787,\tbest of gen size: 6\n",
      "gen: 11,\tbest of gen fitness: -3229.755,\tbest of gen size: 5\n",
      "gen: 12,\tbest of gen fitness: -3229.755,\tbest of gen size: 5\n",
      "gen: 13,\tbest of gen fitness: -3229.755,\tbest of gen size: 5\n",
      "gen: 14,\tbest of gen fitness: -3197.034,\tbest of gen size: 17\n",
      "gen: 15,\tbest of gen fitness: -3164.024,\tbest of gen size: 15\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from genepro.scikit import GeneProRegressor\n",
    "from genepro.node_impl import *\n",
    "\n",
    "# Let's load the Diabetes data set from sklearn\n",
    "X, y = load_diabetes(return_X_y=True)\n",
    "\n",
    "# Create a train and test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply feature normalization\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Set up what nodes genepro should use\n",
    "internal_nodes = [Plus(), Minus(), Times(), Div(), Log()]\n",
    "\n",
    "# Create a score (higher = better) from the mean squared error (lower = better) by taking -mse\n",
    "def neg_mse(y, p):\n",
    "  return -mean_squared_error(y, p)\n",
    "\n",
    "# Set up regressor\n",
    "gp = GeneProRegressor(neg_mse, internal_nodes, \n",
    "  use_linear_scaling=True, # linear scaling applies a linear layer to the prediction (intercept + slope*prediction) \n",
    "  evo_kwargs={'verbose': True, 'pop_size': 128, 'max_gens': 40, 'max_tree_size': 50, 'n_jobs': 4, })\n",
    "\n",
    "# Run\n",
    "gp.fit(X_train, y_train)\n",
    "\n",
    "# Get test negative mean squared error\n",
    "test_neg_mse = neg_mse(y_test, gp.predict(X_test))\n",
    "print(\"The negative mean squared error on the test set is {:.3f} (respective R^2 score is {:.3f})\".format(\n",
    "  test_neg_mse, 1 + test_neg_mse/np.var(y_train)))\n",
    "# Get the best-found tree (at the last generation) and simplify it\n",
    "best_tree = sympy.simplify(gp.evo.best_of_gens[-1].get_readable_repr())\n",
    "print(\"Obtained by the (simplified) model:\", best_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "82b2f7e49a54dfc9e19a85f649bd0ef29fcdbc801e6c42932c693ea93cc5c6ab"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
