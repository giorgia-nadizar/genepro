{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification and regression with genepro\n",
    "A Scikit-learn compatible classifier and regressor is already provided in genepro. This notebook show how they can be used.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification\n",
    "At the moment, genepro supports binary classification. The reason why multi-class is not supported is that the output of a tree is its root, hence a multi-tree representation is required to realize multi-class classification. Here's how binary classification can be performed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen: 1,\tbest of gen fitness: 0.807,\tbest of gen size: 21\n",
      "gen: 2,\tbest of gen fitness: 0.846,\tbest of gen size: 24\n",
      "gen: 3,\tbest of gen fitness: 0.862,\tbest of gen size: 24\n",
      "gen: 4,\tbest of gen fitness: 0.842,\tbest of gen size: 24\n",
      "gen: 5,\tbest of gen fitness: 0.885,\tbest of gen size: 8\n",
      "gen: 6,\tbest of gen fitness: 0.885,\tbest of gen size: 8\n",
      "gen: 7,\tbest of gen fitness: 0.885,\tbest of gen size: 8\n",
      "gen: 8,\tbest of gen fitness: 0.886,\tbest of gen size: 32\n",
      "gen: 9,\tbest of gen fitness: 0.886,\tbest of gen size: 32\n",
      "gen: 10,\tbest of gen fitness: 0.886,\tbest of gen size: 32\n",
      "gen: 11,\tbest of gen fitness: 0.886,\tbest of gen size: 45\n",
      "gen: 12,\tbest of gen fitness: 0.909,\tbest of gen size: 36\n",
      "gen: 13,\tbest of gen fitness: 0.909,\tbest of gen size: 9\n",
      "gen: 14,\tbest of gen fitness: 0.909,\tbest of gen size: 46\n",
      "gen: 15,\tbest of gen fitness: 0.931,\tbest of gen size: 34\n",
      "gen: 16,\tbest of gen fitness: 0.931,\tbest of gen size: 34\n",
      "gen: 17,\tbest of gen fitness: 0.931,\tbest of gen size: 34\n",
      "gen: 18,\tbest of gen fitness: 0.931,\tbest of gen size: 34\n",
      "gen: 19,\tbest of gen fitness: 0.931,\tbest of gen size: 34\n",
      "gen: 20,\tbest of gen fitness: 0.931,\tbest of gen size: 38\n",
      "gen: 21,\tbest of gen fitness: 0.931,\tbest of gen size: 34\n",
      "gen: 22,\tbest of gen fitness: 0.931,\tbest of gen size: 49\n",
      "gen: 23,\tbest of gen fitness: 0.931,\tbest of gen size: 35\n",
      "gen: 24,\tbest of gen fitness: 0.937,\tbest of gen size: 44\n",
      "gen: 25,\tbest of gen fitness: 0.937,\tbest of gen size: 44\n",
      "gen: 26,\tbest of gen fitness: 0.937,\tbest of gen size: 44\n",
      "gen: 27,\tbest of gen fitness: 0.937,\tbest of gen size: 44\n",
      "gen: 28,\tbest of gen fitness: 0.937,\tbest of gen size: 44\n",
      "gen: 29,\tbest of gen fitness: 0.937,\tbest of gen size: 48\n",
      "gen: 30,\tbest of gen fitness: 0.937,\tbest of gen size: 44\n",
      "gen: 31,\tbest of gen fitness: 0.937,\tbest of gen size: 44\n",
      "gen: 32,\tbest of gen fitness: 0.937,\tbest of gen size: 44\n",
      "gen: 33,\tbest of gen fitness: 0.937,\tbest of gen size: 44\n",
      "gen: 34,\tbest of gen fitness: 0.941,\tbest of gen size: 44\n",
      "gen: 35,\tbest of gen fitness: 0.944,\tbest of gen size: 44\n",
      "gen: 36,\tbest of gen fitness: 0.944,\tbest of gen size: 44\n",
      "gen: 37,\tbest of gen fitness: 0.944,\tbest of gen size: 50\n",
      "gen: 38,\tbest of gen fitness: 0.944,\tbest of gen size: 44\n",
      "gen: 39,\tbest of gen fitness: 0.944,\tbest of gen size: 35\n",
      "gen: 40,\tbest of gen fitness: 0.944,\tbest of gen size: 42\n",
      "The balanced accuracy on the test set is 0.979\n",
      "Obtained by the (simplified) model: -x12*x20*(0.4770220891464307*x11 + x5) - x20 - x7\n"
     ]
    }
   ],
   "source": [
    "import sympy\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from genepro.scikit import GeneProClassifier\n",
    "from genepro.node_impl import *\n",
    "\n",
    "# Let's load the Breast Cancer data set from sklearn\n",
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "\n",
    "# Create a train and test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply feature normalization\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Set up what nodes genepro should use\n",
    "internal_nodes = [Plus(), Minus(), Times(), Div(), Log()]\n",
    "# As leaf nodes, let's set up the possibility to use each feature, plus a constant\n",
    "# (this is the default if leaf_nodes are not provided)\n",
    "num_features = X_train.shape[1]\n",
    "leaf_nodes = [Feature(i) for i in range(num_features)] + [Constant()]\n",
    "\n",
    "# Set up classifier\n",
    "gp = GeneProClassifier(balanced_accuracy_score, internal_nodes, leaf_nodes=leaf_nodes, \n",
    "  evo_kwargs={'verbose':True, 'pop_size':128, 'max_gens':40, 'max_tree_size':50, 'n_jobs':4, })\n",
    "\n",
    "# Run\n",
    "gp.fit(X_train, y_train)\n",
    "\n",
    "# Get test (balanced) accuracy\n",
    "test_acc = balanced_accuracy_score(y_test, gp.predict(X_test))\n",
    "print(\"The balanced accuracy on the test set is {:.3f}\".format(test_acc))\n",
    "# Get the best-found tree (at the last generation) and simplify it\n",
    "best_tree = sympy.simplify(gp.evo.best_of_gens[-1].get_readable_repr())\n",
    "print(\"Obtained by the (simplified) model:\", best_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen: 1,\tbest of gen fitness: -4976.291,\tbest of gen size: 5\n",
      "gen: 2,\tbest of gen fitness: -3854.131,\tbest of gen size: 3\n",
      "gen: 3,\tbest of gen fitness: -3854.131,\tbest of gen size: 3\n",
      "gen: 4,\tbest of gen fitness: -3854.131,\tbest of gen size: 3\n",
      "gen: 5,\tbest of gen fitness: -3552.603,\tbest of gen size: 5\n",
      "gen: 6,\tbest of gen fitness: -3307.134,\tbest of gen size: 5\n",
      "gen: 7,\tbest of gen fitness: -3307.134,\tbest of gen size: 5\n",
      "gen: 8,\tbest of gen fitness: -3307.134,\tbest of gen size: 5\n",
      "gen: 9,\tbest of gen fitness: -3307.134,\tbest of gen size: 5\n",
      "gen: 10,\tbest of gen fitness: -3229.755,\tbest of gen size: 5\n",
      "gen: 11,\tbest of gen fitness: -3229.755,\tbest of gen size: 5\n",
      "gen: 12,\tbest of gen fitness: -3229.755,\tbest of gen size: 5\n",
      "gen: 13,\tbest of gen fitness: -3229.755,\tbest of gen size: 7\n",
      "gen: 14,\tbest of gen fitness: -3169.673,\tbest of gen size: 17\n",
      "gen: 15,\tbest of gen fitness: -3169.673,\tbest of gen size: 17\n",
      "gen: 16,\tbest of gen fitness: -3154.559,\tbest of gen size: 9\n",
      "gen: 17,\tbest of gen fitness: -3154.559,\tbest of gen size: 9\n",
      "gen: 18,\tbest of gen fitness: -3142.446,\tbest of gen size: 21\n",
      "gen: 19,\tbest of gen fitness: -3142.446,\tbest of gen size: 21\n",
      "gen: 20,\tbest of gen fitness: -3142.446,\tbest of gen size: 21\n",
      "gen: 21,\tbest of gen fitness: -3142.446,\tbest of gen size: 21\n",
      "gen: 22,\tbest of gen fitness: -3142.446,\tbest of gen size: 21\n",
      "gen: 23,\tbest of gen fitness: -3142.446,\tbest of gen size: 21\n",
      "gen: 24,\tbest of gen fitness: -3077.718,\tbest of gen size: 26\n",
      "gen: 25,\tbest of gen fitness: -3077.718,\tbest of gen size: 26\n",
      "gen: 26,\tbest of gen fitness: -3077.718,\tbest of gen size: 26\n",
      "gen: 27,\tbest of gen fitness: -3051.838,\tbest of gen size: 30\n",
      "gen: 28,\tbest of gen fitness: -3051.838,\tbest of gen size: 30\n",
      "gen: 29,\tbest of gen fitness: -3051.838,\tbest of gen size: 30\n",
      "gen: 30,\tbest of gen fitness: -3040.892,\tbest of gen size: 38\n",
      "gen: 31,\tbest of gen fitness: -3040.045,\tbest of gen size: 38\n",
      "gen: 32,\tbest of gen fitness: -3039.306,\tbest of gen size: 40\n",
      "gen: 33,\tbest of gen fitness: -3039.306,\tbest of gen size: 40\n",
      "gen: 34,\tbest of gen fitness: -3039.306,\tbest of gen size: 40\n",
      "gen: 35,\tbest of gen fitness: -3039.306,\tbest of gen size: 40\n",
      "gen: 36,\tbest of gen fitness: -3010.345,\tbest of gen size: 43\n",
      "gen: 37,\tbest of gen fitness: -2964.086,\tbest of gen size: 44\n",
      "gen: 38,\tbest of gen fitness: -3010.345,\tbest of gen size: 43\n",
      "gen: 39,\tbest of gen fitness: -2998.565,\tbest of gen size: 43\n",
      "gen: 40,\tbest of gen fitness: -2986.394,\tbest of gen size: 45\n",
      "The negative mean squared error on the test set is -2757.157 (respective R^2 score is 0.546)\n",
      "Obtained by the (simplified) model: 5*x2 + 3*x3 - x6 + 3*x8 + log(abs(x9)) + log(abs(2*x2 + x8 + 1.4428331964345844)) - 9.2661938691054493\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from genepro.scikit import GeneProRegressor\n",
    "from genepro.node_impl import *\n",
    "\n",
    "# Let's load the Diabetes data set from sklearn\n",
    "X, y = load_diabetes(return_X_y=True)\n",
    "\n",
    "# Create a train and test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply feature normalization\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Set up what nodes genepro should use\n",
    "internal_nodes = [Plus(), Minus(), Times(), Div(), Log()]\n",
    "\n",
    "# Create a score (higher = better) from the mean squared error (lower = better) by taking -mse\n",
    "def neg_mse(y, p):\n",
    "  return -mean_squared_error(y, p)\n",
    "\n",
    "# Set up regressor\n",
    "gp = GeneProRegressor(neg_mse, internal_nodes, \n",
    "  use_linear_scaling=True, # linear scaling applies a linear layer to the prediction (intercept + slope*prediction) \n",
    "  evo_kwargs={'verbose': True, 'pop_size': 128, 'max_gens': 40, 'max_tree_size': 50, 'n_jobs': 4, })\n",
    "\n",
    "# Run\n",
    "gp.fit(X_train, y_train)\n",
    "\n",
    "# Get test negative mean squared error\n",
    "test_neg_mse = neg_mse(y_test, gp.predict(X_test))\n",
    "print(\"The negative mean squared error on the test set is {:.3f} (respective R^2 score is {:.3f})\".format(\n",
    "  test_neg_mse, 1 + test_neg_mse/np.var(y_train)))\n",
    "# Get the best-found tree (at the last generation) and simplify it\n",
    "best_tree = sympy.simplify(gp.evo.best_of_gens[-1].get_readable_repr())\n",
    "print(\"Obtained by the (simplified) model:\", best_tree)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "82b2f7e49a54dfc9e19a85f649bd0ef29fcdbc801e6c42932c693ea93cc5c6ab"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
